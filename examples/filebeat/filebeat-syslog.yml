filebeat.inputs:
- type: syslog
  protocol.udp:
    host: "${SYSLOG_UDP_HOST:0.0.0.0}:${SYSLOG_UDP_PORT:5514}"
  protocol.tcp:
    host: "${SYSLOG_TCP_HOST:0.0.0.0}:${SYSLOG_TCP_PORT:5514}"

processors:
- add_fields:
    target: data_stream
    fields:
      type: ${DATA_STREAM_TYPE:logs}
      dataset: ${DATA_STREAM_DATASET:syslog.rfc3164}
      namespace: ${DATA_STREAM_NAMESPACE:default}
- add_fields:
    target: service
    fields:
      name: ${SERVICE_NAME:filebeat}
- add_host_metadata: ~
- add_cloud_metadata: ~

setup.template.enabled: false
setup.ilm.enabled: false

output.elasticsearch:
  hosts: [ "${ES_HOSTS:https://localhost:9200}" ]
  username: "${ES_USERNAME:elastic}"
  password: "${ES_PASSWORD:changeme}"
  ssl.verification_mode: ${ES_SSL_VERIFY:full}
  index: "logs-%{[data_stream.dataset]}-%{[data_stream.namespace]}"

# Alternative: Logstash output (uncomment to use)
#output.logstash:
#  hosts: [ "${LOGSTASH_HOSTS:localhost:5044}" ]
#  #loadbalance: true
#  #ssl.enabled: false
#  #ssl.certificate_authorities: ["/etc/pki/tls/certs/ca-bundle.crt"]

# Alternative: Kafka output (uncomment to use)
#output.kafka:
#  hosts: [ "${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}" ]
#  topic: "${KAFKA_TOPIC:logs}"
#  partition.round_robin.reachable_only: true
#  required_acks: 1
#  compression: gzip
#  max_message_bytes: 1000000
#  codec.json:
#    pretty: false

logging.level: info
logging.json: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  rotateeverybytes: 10485760

http.enabled: true
http.host: localhost
http.port: 5066
