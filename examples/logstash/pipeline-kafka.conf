input {
  kafka {
    bootstrap_servers => "${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}"
    topics => [ "${KAFKA_TOPICS:logs}" ]
    group_id => "${KAFKA_GROUP_ID:logstash}"
    codec => json
    enable_auto_commit => true
    auto_offset_reset => "latest"
    # For SASL/SSL enablement see plugin docs; common envs you might export:
    # security_protocol => "SASL_SSL"
    # sasl_mechanism => "PLAIN"
    # sasl_jaas_config => "org.apache.kafka.common.security.plain.PlainLoginModule required username='${KAFKA_SASL_USERNAME}' password='${KAFKA_SASL_PASSWORD}';"
  }
}

filter {
}

output {
  elasticsearch {
    hosts => [ "${ES_HOSTS:https://localhost:9200}" ]
    user => "${ES_USERNAME:elastic}"
    password => "${ES_PASSWORD:changeme}"
    # api_key => "${ES_API_KEY}"
    data_stream => true
    data_stream_type => "${DATA_STREAM_TYPE:logs}"
    data_stream_dataset => "${DATA_STREAM_DATASET:kafka.generic}"
    data_stream_namespace => "${DATA_STREAM_NAMESPACE:default}"
    ilm_enabled => false
    # cacert => "${ES_CACERT}"
  }
}
