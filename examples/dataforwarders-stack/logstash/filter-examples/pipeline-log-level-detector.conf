input {
  http {
    host => "${HTTP_HOST:0.0.0.0}"
    port => "${HTTP_PORT:8089}"
    additional_codecs => { "application/json" => "json" }
  }
}

filter {
  mutate { convert => { "message" => "string" } }

  json {
    source => "message"
    tag_on_failure => ["_json_parse_failure"]
  }

  if "_json_parse_failure" in [tags] {
    kv {
      source => "message"
      field_split => "\s+"
      value_split => "="
      include_brackets => true
    }
    mutate { add_tag => ["_kv_parsed"] }
  }

  if "_json_parse_failure" in [tags] and "_kv_parsed" not in [tags] {
    grok {
      match => {
        "message" => [
          "%{TIMESTAMP_ISO8601:ts}\s+%{LOGLEVEL:level}\s+%{GREEDYDATA:log_message}",
          "%{TIMESTAMP_ISO8601:ts}\s+\[%{LOGLEVEL:level}\]\s+%{GREEDYDATA:log_message}",
          "\[%{LOGLEVEL:level}\]\s+%{GREEDYDATA:log_message}"
        ]
      }
      tag_on_failure => ["_line_parse_failure"]
    }
    date {
      match => ["ts", "ISO8601"]
      target => "@timestamp"
    }
  }

  if [level] {
    mutate { lowercase => ["level"] }
  } else if [log.level] {
    mutate { add_field => { "level" => "%{[log][level]}" } }
    mutate { lowercase => ["level"] }
  } else if [severity] {
    mutate { add_field => { "level" => "%{[severity]}" } }
    mutate { lowercase => ["level"] }
  }

  if [level] and [level] in ["debug"] {
    drop { }
  }
}

output {
  elasticsearch {
    hosts => [ "${ES_HOSTS:https://localhost:9200}" ]
    user => "${ES_USERNAME:elastic}"
    password => "${ES_PASSWORD:changeme}"
    data_stream => true
    data_stream_type => "logs"
    data_stream_dataset => "auto.level_detected"
    data_stream_namespace => "${DATA_STREAM_NAMESPACE:default}"
    ilm_enabled => false
  }
}


